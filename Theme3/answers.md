Тема 3. Метричні методи розв’язання задачі класифікації.
1.	Поняття метріки. Аксіоми. Приклади метрік (Евклідова метріка, метріка Міньковського).
2.	Гіпотези компактності та неперервності.

Гіпотеза компактності - близькі об'єкти, як правило, належать одному класу. (для задачі класифікації)

Гіпотеза неперервності - близьким об'єктам відповідають близькі значення. (для задачі регресії)

3.	Метричний алгоритм класифікації.

Один з найпростіших методів класифікації, який базується на оцінюванні подібності об'єктів. Об'єкт, який класифікують, відноситься до того класу, якому належать найближчі до нього об'єкти навчальної вибірки.

![KNN](http://www.machinelearning.ru/mimetex/?a(u)%20=%20\mathrm{arg}\max_{y\in%20Y}%20\sum_{i=1}^m%20\bigl[%20x_{i;%20u}=y%20\bigr]%20w(i,u),)

При `k=1` , метод найближчих сусідів стає нестійким та часто класифікує об'єкт неправильно. При `k=m` (`m - кількість об'єктів навчальної вибірки`), метод навпаки стає стійким, та набуває значення константи. Саме тому, граничні значення сусідів бажано не використовувати. На практиці, для визначення оптимального значення `k` використовують рухливий контроль LOO (leave-one-out) (див. Тема 2, №5).

4.	Метод KNN (k найближчих сусідів). Вибір параметру k.
5.	Метод k зважених найближчих сусідів.

K зважених найближчих сусідів - метричний алгоритм класифікації, що базується на оцінюванні схожості об'єктів. Класифікуємий об'єкт належить тому класу, котрому належать найближчі до нього об'єкти навчальної виборки. 

Алгоритм - [Алгоритм](http://www.machinelearning.ru/mimetex/?a(u)%20=%20\mathrm{arg}\max_{y\in%20Y}%20\sum_{i=1}^m%20\bigl[%20x_{i;%20u}=y%20\bigr]%20w(i,u),)
Де w(i,x) — задана вагова функція, що оцінює степінь важливості i-го сусіда для класифікації об'єкта. Так, за w(i,x)=1 при i<k алгоритм відповідає медоду k найближчих сусідів. Але для задачі з кількома можливими відповідями максимальна сума "важливості" може досягатись на кількох класах одночасно. Неоднозначність можна нівелювати, якщо за вагову функцію обрати нелінійну послідовність.

6.	Метод вікна Парзена фіксованої ширини.

Метод вікна Парзена - метод баєсівської класифікації, заснований на непараметричному відновленні щільності по заданій вибірці.

Основою підходу є ідея про те, що щільність вище в тих точках, поряд з якими є велика кількість об'єктів виборки. Якщо потужність множини елементарних результатів значно менша від розміру вибірки, то замість відновленої за вибіркою ми можемо взяти й гістограму значень вибірки.

Парзенівська оцінка щільності - ![Парзенівська оцінка щільності](http://www.machinelearning.ru/mimetex/?p_{y,h}(x)%20=%20\frac{1}{l_y%20V(h)}%20\sum_{i=1}^l%20[y_i%20=%20y]%20K(\frac{\rho(x,%20x_i)}{h}))

7.	Поняття ядра. Основні вимоги та приклади.
8.	Метод вікна Парзена змінної ширини.
