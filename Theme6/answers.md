Тема 6. Байєсовські методи класифікації. 
1.	Умовна ймовірність. Формула повної ймовірності. Формула Байєса.
	**Умовна ймовірність.**
	Нехай ( Ω , F , P ) — фіксований ймовірнісний простір. Нехай  A , B ∈ F - дві випадкової події, причому P ( B ) > 0 . Тоді умовною ймовірністю події  A  при умові події  B називається ![{\displaystyle \mathbb {P} (A\vert B)={\frac {\mathbb {P} (A\cap B)}{\mathbb {P} (B)}}.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8601840fef29f86cfa1b3b60d8d29bd9b1ff6a1d)
	**Формула повної ймовірності.** 
	Нехай в умовах експерименту подія A з'являється спільно з однією з групи несумісних подій (гіпотез) Hi(i=1,...,n), що утворюють повну групу ![](http://yukhym.com/images/stories/Imov/Im3_003.gif), відомі або можливо встановити апріорні ймовірністі P(Hi) кожної з гіпотез та умовні ймовірності P(A/Hi) події A за умови, що здійснилася та або інша гіпотеза, тоді ймовірність події A визначається за формулою повної ймовірності:  
![](http://yukhym.com/images/stories/Imov/Im3_008.gif)

	де P(Hi)– ймовірність гіпотези Hi;  
	P(A/Hi)– умовна ймовірність події ![](http://yukhym.com/images/stories/Imov/Im3_001.gif) при виконанні гіпотези Hi. Наведена формула називається **формулою повної ймовірності (1.1).**
		**Формула Байєса.**
		Отримавши 1.1, нас цікавить, як зміняться ймовірності гіпотез ![](https://web.posibnyky.vntu.edu.ua/fitki/4tichinska_teoriya_jmovirnostej/17_src/17_image017.png), _і_= 1, 2…, _n_, якщо подія _А_ відбулась. Тобто, як обчислити ![](https://web.posibnyky.vntu.edu.ua/fitki/4tichinska_teoriya_jmovirnostej/17_src/17_image019.png). Справедливі рівності:![](https://web.posibnyky.vntu.edu.ua/fitki/4tichinska_teoriya_jmovirnostej/17_src/17_image021.png) ![](https://web.posibnyky.vntu.edu.ua/fitki/4tichinska_teoriya_jmovirnostej/17_src/17_image023.png), звідки

	![](https://web.posibnyky.vntu.edu.ua/fitki/4tichinska_teoriya_jmovirnostej/17_src/17_image025.png) (1.2)

	Ця формула називається формулою **Байєса**.
	Наведені формули дозволяють проводити міркування в умовах невизначеності, а тому мають безпосереднє застосування у байєсівському підході до теорії ймовірностей (яку можна розглядати як узагальнення класичної булевської логіки); побудовані на цьому методи машинного навчання нащиваються байєсівськими.
2.	Байєсовська (ймовірностна) постановка задачі МН. Принцип максимуму апосторіорної ймовірності.
3.	Оптимальний байєсовський  класифікатор. Теорема існування.
4.	Наївний байєсовський  класифікатор.
5.	Відновлення одномірної щільності розподілу.
6.	Оцінка щільності розподілу методом парзенівського вікна. Основні типи ядер.
